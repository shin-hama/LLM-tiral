{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swallow\n",
    "\n",
    "<https://huggingface.co/tokyotech-llm/Swallow-13b-instruct-hf>\n",
    "\n",
    "Our Swallow model has undergone continuous pre-training from the Llama 2 family, primarily with the addition of Japanese language data. The tuned versions use supervised fine-tuning (SFT). Links to other models can be found in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamada\\workspace\\test\\llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proxy の無効化\n",
    "\n",
    "!set HTTP_PROXY=\"\"\n",
    "!set HTTPS_PROXY=\"\"\n",
    "\n",
    "import sys,os,os.path\n",
    "\n",
    "os.environ['HTTP_PROXY']=\"\"\n",
    "os.environ['HTTPS_PROXY']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00006.safetensors: 100%|██████████| 4.99G/4.99G [01:30<00:00, 54.9MB/s]\n",
      "model-00002-of-00006.safetensors: 100%|██████████| 4.97G/4.97G [01:25<00:00, 58.4MB/s]\n",
      "model-00003-of-00006.safetensors: 100%|██████████| 4.93G/4.93G [03:52<00:00, 21.2MB/s]\n",
      "model-00004-of-00006.safetensors: 100%|██████████| 4.93G/4.93G [02:38<00:00, 31.1MB/s]\n",
      "model-00005-of-00006.safetensors: 100%|██████████| 4.93G/4.93G [01:20<00:00, 61.2MB/s]\n",
      "model-00006-of-00006.safetensors: 100%|██████████| 1.50G/1.50G [00:48<00:00, 31.0MB/s]\n",
      "Downloading shards: 100%|██████████| 6/6 [11:39<00:00, 116.58s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
      "generation_config.json: 100%|██████████| 203/203 [00:00<?, ?B/s] \n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"tokyotech-llm/Swallow-70b-instruct-hf\"\n",
    "model_name = \"tokyotech-llm/Swallow-13b-instruct-hf\"\n",
    "# model_name = \"tokyotech-llm/Swallow-7b-instruct-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, low_cpu_mem_usage=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。\"\n",
    "        \"リクエストを適切に完了するための回答を記述してください。\\n\\n\"\n",
    "        \"### 指示:\\n{instruction}\\n\\n### 入力:\\n{input}\\n\\n### 応答:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"以下に、あるタスクを説明する指示があります。\"\n",
    "        \"リクエストを適切に完了するための回答を記述してください。\\n\\n\"\n",
    "        \"### 指示:\\n{instruction}\\n\\n### 応答:\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def create_prompt(instruction, input=None):\n",
    "    \"\"\"\n",
    "    Generates a prompt based on the given instruction and an optional input.\n",
    "    If input is provided, it uses the 'prompt_input' template from PROMPT_DICT.\n",
    "    If no input is provided, it uses the 'prompt_no_input' template.\n",
    "\n",
    "    Args:\n",
    "        instruction (str): The instruction describing the task.\n",
    "        input (str, optional): Additional input providing context for the task. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated prompt.\n",
    "    \"\"\"\n",
    "    if input:\n",
    "        # Use the 'prompt_input' template when additional input is provided\n",
    "        return PROMPT_DICT[\"prompt_input\"].format(instruction=instruction, input=input)\n",
    "    else:\n",
    "        # Use the 'prompt_no_input' template when no additional input is provided\n",
    "        return PROMPT_DICT[\"prompt_no_input\"].format(instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力はとあるソフトウェアのインターフェースを説明した文章です。入力内容を英語に翻訳してください。\n",
      "\n",
      "### 入力:\n",
      "View のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\n",
      "\n",
      "### 応答:If the constructor of the View requires ViewModel as an argument, pass the ViewModel argument passed to the constructor into the method argument.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "instruction = \"入力はとあるソフトウェアのインターフェースを説明した文章です。入力内容を英語に翻訳してください。\"\n",
    "input_example = \"View のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\"\n",
    "prompt = create_prompt(instruction, input_example)\n",
    "\n",
    "input_ids = tokenizer.encode(\n",
    "    prompt,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "tokens = model.generate(\n",
    "    input_ids.to(device=model.device),\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.99,\n",
    "    top_p=0.95,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "out = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "指定された ID に紐づけられた型を取得する\n",
      "\n",
      "\n",
      "### 応答:Get the type associated with the specified ID.\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "View のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\n",
      "\n",
      "\n",
      "### 応答:\n",
      "View のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\n",
      "\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "カメラの動作状態を格納するクラスです。\n",
      "\n",
      "\n",
      "### 応答:カメラの動作状態を格納するクラスです。\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "IN/OUT状態を表す列挙型です。\n",
      "\n",
      "\n",
      "### 応答:状態を表す列挙型IN/OUTです。\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "指定された型に対する登録が複数ある場合のための、登録内容を識別する名前 (キー)\n",
      "\n",
      "\n",
      "### 応答:\n",
      "Register name that identifies registration content for a type that can be applied to multiple types.\n",
      "\n",
      "[以下では、上記の日本語入力の英訳を掲載する。]\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "登録されていれば <a href=\"https://learn.microsoft.com/dotnet/csharp/language-reference/builtin-types/bool\">true</a> を返し、そうでない場合は <a href=\"https://learn.microsoft.com/dotnet/csharp/language-reference/builtin-types/bool\">false</a> を返します。\n",
      "\n",
      "\n",
      "### 応答:登録されていれば <span>true</span> を返し、そうでない場合は <span>false</span> を返します。\n",
      "\n",
      "入力3\n",
      "回答:これらを用いて、この関数を呼び出す際には、それぞれの要素の名前でアクセスできることを確認してください。\n",
      "\n",
      "入力4\n",
      "回答:これらの関数では、それぞれ2つの値を受け取り、その値がある値以上であるか、以下であるかを確認しています。\n",
      "\n",
      "入力5\n",
      "回答:これらの関数は、受け取った要素\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "指定された実装型を、指定された型に紐づけて、ライフライクル (スコープ) を Singleton として、コンテナに登録する\n",
      "\n",
      "\n",
      "### 応答:\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "登録されていれば\n",
      "\n",
      "\n",
      "### 応答:You have already been registered with it.\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "true\n",
      "\n",
      "\n",
      "### 応答:\n",
      "\n",
      "true\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "を返し、そうでない場合は\n",
      "\n",
      "\n",
      "### 応答:\n",
      "を返し、そうでない場合は\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "false\n",
      "\n",
      "\n",
      "### 応答:false\n",
      "以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\n",
      "\n",
      "### 指示:\n",
      "入力内用はとあるソフトウェアのインターフェースを説明した文章です。入力内用を英語に翻訳してください。また、応答には翻訳した文章のみを出力してください\n",
      "\n",
      "### 入力:\n",
      "を返します。\n",
      "\n",
      "\n",
      "### 応答:The operation returns a string representing the current version of the application.\n"
     ]
    }
   ],
   "source": [
    "# read input file\n",
    "file_name = \"../inputs.txt\"\n",
    "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    prompt = create_prompt(instruction, line)\n",
    "\n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    tokens = model.generate(\n",
    "        input_ids.to(device=model.device),\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.99,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    out = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "    print(out)\n",
    "    print(\"/n===/n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
