{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLaMo\n",
    "\n",
    "https://huggingface.co/pfnet/plamo-13b#plamo-13b\n",
    "\n",
    "PLaMo-13B is a LLaMA-based 13B model pre-trained on English and Japanese open datasets, developed by Preferred Networks, Inc. PLaMo-13B is released under Apache v2.0 license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proxy の無効化\n",
    "\n",
    "!set HTTP_PROXY=\"\"\n",
    "!set HTTPS_PROXY=\"\"\n",
    "\n",
    "import sys,os,os.path\n",
    "\n",
    "os.environ['HTTP_PROXY']=\"\"\n",
    "os.environ['HTTPS_PROXY']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00003.safetensors: 100%|██████████| 9.95G/9.95G [02:34<00:00, 64.5MB/s]\n",
      "model-00002-of-00003.safetensors: 100%|██████████| 9.90G/9.90G [02:36<00:00, 63.1MB/s]\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 6.35G/6.35G [03:44<00:00, 28.3MB/s]\n",
      "Downloading shards: 100%|██████████| 3/3 [08:57<00:00, 179.03s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:47<00:00, 15.75s/it]\n",
      "generation_config.json: 100%|██████████| 153/153 [00:00<?, ?B/s] \n",
      "tokenizer_config.json: 100%|██████████| 488/488 [00:00<?, ?B/s] \n",
      "tokenization_plamo.py: 100%|██████████| 5.93k/5.93k [00:00<00:00, 5.93MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/pfnet/plamo-13b:\n",
      "- tokenization_plamo.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "tokenizer.model: 100%|██████████| 1.12M/1.12M [00:00<00:00, 35.1MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 170/170 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '次の文章を英訳してください。なお応答内用は英訳された文章だけを返してください。｢View のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。｣\\nView のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\\nView '}]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "model = \"pfnet/plamo-13b\"\n",
    "\n",
    "pipeline = transformers.pipeline(\"text-generation\", model=model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。リクエストを適切に完了するための回答を記述してください。\\n\\n### 指示:\\n入力はとあるソフトウェアのインターフェースを説明した文章です。入力内容を英語に翻訳してください。また、応答には英語に翻訳された文章のみを出力してください\\n\\n### 入力:\\nView のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\\n\\n### 応答:\\nView のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を返します。\\n\\n###'}]\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(task: str, inputs: str) -> str:\n",
    "    return (\n",
    "        \"以下に、あるタスクを説明する指示があり、それに付随する入力が更なる文脈を提供しています。\"\n",
    "        \"リクエストを適切に完了するための回答を記述してください。\\n\\n\"\n",
    "        f\"### 指示:\\n{task}\\n\\n### 入力:\\n{inputs}\\n\\n### 応答:\"\n",
    "    )\n",
    "\n",
    "instruction = \"入力はとあるソフトウェアのインターフェースを説明した文章です。入力内容を英語に翻訳してください。また、応答には英語に翻訳された文章のみを出力してください\"\n",
    "inputs = \"View のコンストラクタが引数として ViewModel を要求する場合は、このメソッド引数の ViewModel を渡します。\"\n",
    "\n",
    "prompt = create_prompt(instruction, inputs)\n",
    "result = pipeline(prompt, max_new_tokens=32)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
